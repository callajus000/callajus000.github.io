<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Justin Callahan</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My Site</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/P-Arrizon/SDS322E_Project.github.io"></a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<p><br></p>
<div id="predicting-heart-failure-with-various-biological-markers" class="section level1">
<h1>Predicting Heart Failure with Various Biological Markers</h1>
<div id="by-justin-callahan-pedro-arrizon-jennice-herrera-doeun-lee-and-abhinav-mugunda" class="section level3">
<h3>By: Justin Callahan, Pedro Arrizon, Jennice Herrera, Doeun Lee, and Abhinav Mugunda</h3>
</div>
</div>
<div id="introduction" class="section level1">
<h1>Introduction:</h1>
<p>Heart failure is a progressive condition in which the heart is unable to pump enough blood to meet the body’s oxygen demand. Cardiovascular disease causes 17.9 million deaths per year, making it the leading cause of death globally. Additionally, heart disease cost the United States $363 billion in 2016 due to health care services, medicine, and lost productivity. The motivation behind this project is to improve the accuracy of heart diagnoses. Statistical models can bring a lot of value to the field of health care, and cardiology specifically. Their use could allow health professionals to more accurately select which health factors to prioritize when diagnosing patients. By understanding the impact that various biological markers have on an individual’s likelihood of developing heart failure, preventative measures can be more effective.</p>
<p></br></p>
</div>
<div id="data" class="section level1">
<h1>Data:</h1>
<p>The dataset our group used is one that was downloaded from Kaggle. It contains real data documenting factors related to heart health compiled from datasets put out by hospitals in Virginia, Cleveland, Hungary, and Switzerland. There were originally 1,190 observations in the dataset, but 272 duplicates were removed, leaving 918 observations in the final data we analyzed. The data needed several transformations in order to make it easier to analyze. Sex was turned into a binary variable, where 1 is male and 0 is female. ChestPainType was turned into a binary variable, where asymptomatic is 1, and the three types of symptomatic pain were 0. ST_Slope was turned into a binary variable where 1 is flat, and 0 is sloped. Apart from turning some categorical variables into binary variables, the data did not need to be cleaned, as the data set provided on Kaggle had already been cleaned.</p>
<p><img src="data1.jpg" /></p>
<p>The figure above shows the first five rows of data after the transformations. The first eleven variables are the predictor variables, while the last is the target variable. Most of the variables are fairly self explanatory, however FastingBS stands for fasting blood sugar, and it is a binary variable where it is 1 if over 120 mg/dl.</p>
</div>
<div id="exploratory-analysis" class="section level1">
<h1>Exploratory Analysis:</h1>
<p><img src="data2.jpg" /></p>
<p>The mean age in this data is 53.5, as opposed to 29.6 in the world or 38.5 in the United States. The average resting blood pressure is 132.4, as opposed to ~125 for the average 53 year old. It is also important to note that 55% of people in this dataset developed heart disease. Overall, the people in this study are older and have more health risk factors than the general populace.</p>
<p><img src="data3.jpg" /> <img src="data4.jpg" /> <img src="data5.jpg" /> <img src="data6.jpg" /> <img src="data7.jpg" /> <img src="data8.jpg" /></p>
<p>These charts show some of the main trends and possible predictors of heart disease in the dataset. The effect of asymptomatic pain against the symptomatic ChestPainType categories can be seen above. ST_Slope also has a large difference in Flat against an upward sloped line. Another interesting variable we noted was whether the patient experienced Exercise Angina. While there were a number of patients with heart disease who didn’t experience it, an overwhelming majority of people who did experience angina ended up having some kind of heart disease. Looking at these differences improved our ability to transform the variables accurately in order to make a cleaner model.</p>
<p><img src="data9.jpg" /> Inspecting the data before plugging it into the model is one of the most important parts of data science. This allows us to see possible trends, relationships, or any clear errors that may exist in the data. For example, we can see how variables such as Age and MaxHR are normally distributed, but the Oldpeak variable is skewed right, which needs to be taken into account.</p>
<p>Hypotheses: Based off of the charts above, we predict that a sloped ST segment will have high influence in the patient being classified into the heart problem bin. We also predict that high resting blood pressure will have a strong predictive effect on heart problems.</p>
</div>
<div id="modeling" class="section level1">
<h1>Modeling:</h1>
<p>Our problem was a classification problem. The task was to assign the patients into one of two categories, developing heart problems or not developing heart problems, based on the variables given.</p>
<p><img src="data10.jpg" /></p>
<p>In order to pursue the classification goal, our group decided on using a random forest model, which is a collection of decision tree models. Decision trees work by splitting the predictor feature space into sections. At each split, the model makes a decision in order to make the best model classes. This can lead to problems because these models heavily lean towards only certain features and neglect others. To combat this, we used a random forest. This model creates multiple overgrown trees and uses bootstrapping to help create a low variance model. We chose the random forest model over typical decision trees because regular decision trees are trained to take the best split to maximize the entropy gain(greedy split). A random forest uses a random set of features at each split to decorrelate the features with each other allowing us to account for all predictor features. For the parameters for our model we set up the model to take only 3 predictor features out of our subset of 8 predictor features for each tree. We decided to not prune any of our bootstrapped trees to allow us to limit the amount of bias we introduce into the model, which we further explain in limitations.</p>
</div>
<div id="discussion" class="section level1">
<h1>Discussion:</h1>
<p><img src="data11.jpg" /></p>
<p>Our test data was 230 out of the 918 observations. Of these, there were 200 correct predictions, 21 type 1 errors, and 9 type 2 errors. The accuracy score of .8696 is greater than .7, so this test seems to be successful. On the matrix above, 0 represents negative and 1 represents positive.</p>
<p><img src="data12.jpg" /></p>
<p>Interpreting from the shap value plot, ST_slope and chest pain type were the most important predictors of heart failure, however these two variables were the ones that we manually changed into binary variables. Max Heart Rate and Age were also fairly significant predictors.</p>
<p>Limitations:</p>
<p>For the analysis, we needed to assume independence and randomness of the data collected even though those conditions were not met. Firstly, the data was not randomly chosen. The data had to be collected at the patients consent from the hospitals. This introduces selection bias, as certain patients would be more likely to share their information than others. Secondly, the data was not independent as it was collected from hospitals. People from hospitals often suffer from other complications or are sick in general, so the data may not be representative of the general population. One example of this can be seen in there being a much higher proportion of males in the dataset than in the general population. Another issue with translating the data from the survey to the general population is that the data was only collected from select countries in Europe and select states in the United States. This must be noted before attempting to extrapolate to the rest of the world, as each country has differing foods, traditions, and lifestyles. This lends itself to different health levels in each country, including the frequency of heart problems. When building any model it’s important to take into consideration how much of your own bias you are adding into the model and how it affects it. Changing multiple categorical variables into binary values introduces a lot of bias into the data in order to improve the accuracy of the model. Our lack of medical expertise worked against us here, as we could not confidently assert that these changes were non-material. Because of the bias that was introduced, there is lots of model variance on other potential data sets. In order to progress to future studies, it would be important to bring in someone who is knowledgeable in the field, and could provide insight to help manipulate the predictor features more accurately.</p>
<p><img src="data13.jpg" /> Another possible limitation is that the random forest model is hard to understand up front, and requires interpretation before delivering the results to other groups. It is important to understand the purpose which the model will serve. If the model is too hard for doctors or hospital personnel to understand, they may make life-altering decisions based on incomplete or misleading data.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion:</h1>
<p>It is important to be knowledgeable in the relevant subject when making modeling decisions. Knowing what each variable means and how they interact is key to making usable data. Due to our lack of experience in the field, we chose a model that took choosing factors out of our hand, the random forest model. However, while analyzing the results, it must be noted that relying on only one method is not the most reliable method. The model exists in order to give us information to make decisions with, not to make the decisions for us. Our main finding is that the slope of the ST segment and the type of chest pain are the most important predictors of heart problems, out of the variables given. Further studies of these variables would be necessary in order to determine if our treatment of them was correct, and to what degree they actually affect the populace.</p>
</div>
<div id="acknowledgement" class="section level1">
<h1>Acknowledgement:</h1>
<p>Justin Callahan - Created and presented the data slides on the presentation, compiled the information from the presentation into the essay, and formatted it. Created website.</p>
<p>Pedro Arrizon - Created statistical method models, interpreted and discussed models within group, guided presentation and Final Report.</p>
<p>Jennice Herrera - Helped discuss medical background and terminology, helped guide feature selection within the models using domain experience.</p>
<p>Doeun Lee - Interpreted the resulting graphs, created and presented the result and limitations slides on the presentation, and fixed the final report.</p>
<p>Abhinav Mugunda - Proof read the final report, provided input into project decisions, injected levity into proceedings</p>
</div>
<div id="bibliography" class="section level1">
<h1>Bibliography:</h1>
<p>Divya Jacob, Pharm. D. “What Is the Normal Blood Pressure Range? Chart, Low, Normal &amp; High.” MedicineNet, MedicineNet, 4 Jan. 2021, <a href="https://www.medicinenet.com/blood_pressure_chart_reading_by_age/article.htm" class="uri">https://www.medicinenet.com/blood_pressure_chart_reading_by_age/article.htm</a>.</p>
<p>Fedesoriano. “Heart Failure Prediction Dataset.” Kaggle, 10 Sept. 2021, <a href="https://www.kaggle.com/fedesoriano/heart-failure-prediction" class="uri">https://www.kaggle.com/fedesoriano/heart-failure-prediction</a>.</p>
<p>“Heart Disease Facts.” Centers for Disease Control and Prevention, Centers for Disease Control and Prevention, 27 Sept. 2021, <a href="https://www.cdc.gov/heartdisease/facts.htm" class="uri">https://www.cdc.gov/heartdisease/facts.htm</a>.</p>
<div id="silipo-rosaria.-from-a-single-decision-tree-to-a-random-forest.-medium-towards-data-science-8-oct.-2019-httpstowardsdatascience.comfrom-a-single-decision-tree-to-a-random-forest-b9523be65147." class="section level2">
<h2>Silipo, Rosaria. “From a Single Decision Tree to a Random Forest.” Medium, Towards Data Science, 8 Oct. 2019, <a href="https://towardsdatascience.com/from-a-single-decision-tree-to-a-random-forest-b9523be65147" class="uri">https://towardsdatascience.com/from-a-single-decision-tree-to-a-random-forest-b9523be65147</a>.</h2>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
